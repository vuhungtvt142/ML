{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207c1914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c45684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "import numpy as np\n",
    "def one_hot(ys,num_classes):\n",
    "  one=np.zeros((ys.shape[0],num_classes))\n",
    "  for i, y in enumerate(ys):\n",
    "    one[i][y]=1\n",
    "  return one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89041d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show data\n",
    "import matplotlib.pyplot as plt\n",
    "def show(image,nb_imgs):\n",
    "  fig, axes = plt.subplots(nb_imgs, nb_imgs, figsize=(15, 15))\n",
    "  for i in range(nb_imgs):\n",
    "      for j in range(nb_imgs):\n",
    "          axes[i][j].imshow(image[i*j].reshape(28, 28),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed3d4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data \n",
    "from tensorflow.keras.datasets import mnist \n",
    "def load_data():\n",
    "  (x_train_raw, y_train_raw), (x_val_raw, y_val_raw) = mnist.load_data()\n",
    "  num_classes=len(list(set(y_train_raw)))\n",
    "\n",
    "  x_train=x_train_raw.astype(\"float32\")/255\n",
    "  x_val=x_val_raw.astype(\"float32\")/255\n",
    "\n",
    "  y_train=one_hot(y_train_raw,num_classes)\n",
    "  y_val=one_hot(y_val_raw,num_classes)\n",
    "  return (x_train,y_train),(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf342d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flat data\n",
    "def flat(data):\n",
    "  data_flat=[]\n",
    "  for i in data:\n",
    "    data_flat.append(i.flatten())\n",
    "  data_flat=np.array(data_flat)\n",
    "  return data_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c988d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_val,y_val)=load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5629372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_train,y_train,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27081306",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_flat=flat(x_train)\n",
    "x_test_flat=flat(x_test)\n",
    "x_val_flat=flat(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc2652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of images in val dataset {}\".format(x_val_flat.shape))\n",
    "print(\"Shape of classes in val dataset {}\".format(y_val.shape))\n",
    "print(\"Shape of images in training dataset {}\".format(x_train_flat.shape))\n",
    "print(\"Shape of classes in training dataset {}\".format(y_train.shape))\n",
    "print(\"Shape of images in testing dataset {}\".format(x_test_flat.shape))\n",
    "print(\"Shape of classes in testing dataset {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f81289",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(x_test,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6986137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#placeholder\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "x=tf.compat.v1.placeholder(tf.float32,[None,784]) \n",
    "y=tf.compat.v1.placeholder(tf.float32,[None,10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e928f99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable\n",
    "w=tf.Variable(tf.ones([784,10]))\n",
    "b=tf.cast(tf.Variable(np.random.random(10)),tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f270b30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit=tf.matmul(x,w)+b\n",
    "pred=tf.nn.softmax(logits=logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953569a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating loss of our model\n",
    "entropy=tf.nn.softmax_cross_entropy_with_logits(logits=logit,labels=y)\n",
    "loss = tf.reduce_mean(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c753980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating accuracy of our model \n",
    "correct_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501742e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "learning_rate = 0.01\n",
    "batch_size = 128\n",
    "optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "optimizer1=tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate,\n",
    "    beta1=0.9,\n",
    "    beta2=0.999,\n",
    "    epsilon=1e-08,\n",
    "    use_locking=False,\n",
    "    name='Adam').minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596c4e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.Session()\n",
    "sess.run(tf.compat.v1.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a12450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when using Adam\n",
    "def set_lr(epoch,learning_rate):\n",
    "  if epoch>300:\n",
    "    if epoch%100==0:\n",
    "      learning_rate=learning_rate/10\n",
    "  return learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7cf842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "epochs = 1000\n",
    "train_loss,test_loss,num_epoch,acc=[],[],[],[]\n",
    "for epoch in range(epochs):\n",
    "  learning_rate=set_lr(epoch,learning_rate)  # when using Adam\n",
    "  _,a1=sess.run([optimizer1,loss],feed_dict={x:x_train_flat,y:y_train})\n",
    "  a2,a3=sess.run([loss,accuracy],feed_dict={x:x_val_flat,y:y_val})\n",
    "  train_loss.append(a1)\n",
    "  test_loss.append(a2)\n",
    "  acc.append(a3)\n",
    "  num_epoch.append(epoch)\n",
    "  if epoch%100==0:\n",
    "    print(learning_rate)\n",
    "    print(\"Epochs {} val_loss = {} and train loss = {} and accuracy = {}\".format(epoch, a2,a1,a3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12177bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and accuracy GradientDescentOptimizer\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.title('GradientDescentOptimizer')\n",
    "plt.plot(range(epochs), train_loss,label=\"rain Loss\")\n",
    "plt.plot(range(epochs),test_loss,label=\"test Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(range(epochs),acc,label=\"acc\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5258ca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and accuracy AdamOptimizer\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.title('AdamOptimizer')\n",
    "plt.plot(range(epochs), train_loss,label=\"rain Loss\")\n",
    "plt.plot(range(epochs),test_loss,label=\"test Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(range(epochs),acc,label=\"acc\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8cba43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate in val dataset\n",
    "val_loss, val_acc=sess.run([loss,accuracy],feed_dict={x:x_val_flat,y:y_val})\n",
    "print(\"loss and Accuracy in the validation dataset: {} and {}%\".format(val_loss, val_acc*100))\n",
    "#evaluate in test dataset\n",
    "test_loss, test_acc=sess.run([loss,accuracy],feed_dict={x:x_test_flat,y:y_test})\n",
    "print(\"loss and Accuracy in the testting dataset: {} and {}%\".format(test_loss, test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718e739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = sess.run(pred, feed_dict={x : x_val_flat})\n",
    "true_class=np.argmax(y_val,1)\n",
    "predicted_class=np.argmax(y_pred,1)\n",
    "cm=confusion_matrix(predicted_class,true_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23be787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix GradientDescentOptimizer\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.title('Confusion Matrix')\n",
    "ax=sns.heatmap(cm, annot = True,annot_kws={'size':10},linewidths=1,cmap=plt.cm.Reds)\n",
    "ax.set(xlabel=\"Predicted label\", ylabel=\"True label\")\n",
    "ax.xaxis.tick_top()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dae6df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix AdamOptimizer\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.title('Confusion Matrix')\n",
    "ax=sns.heatmap(cm, annot = True,annot_kws={'size':10},linewidths=1,cmap=plt.cm.Reds)\n",
    "ax.set(xlabel=\"Predicted label\", ylabel=\"True label\")\n",
    "ax.xaxis.tick_top()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b27c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding error outputs\n",
    "y_pred = sess.run(pred, feed_dict={x : x_val_flat})\n",
    "idx=np.argmax(y_pred,1)==np.argmax(y_val,1) \n",
    "cmp=np.where(idx==False) #indices of error outputs\n",
    "# plotting errors\n",
    "fig, axes = plt.subplots(10, 5, figsize=(10,10))\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "cls_true=np.argmax(y_val,1)[cmp]\n",
    "cls_pred=np.argmax(y_pred,1)[cmp]\n",
    "images=x_test[cmp]\n",
    "print(images.shape)\n",
    "for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(images[i].reshape(28,28), cmap='gray')\n",
    "        xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e988cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_grad=[\"GradientDescentOptimizer\",epochs,batch_size,val_loss, val_acc,test_loss, test_acc,sess.run(w),sess.run(b)]\n",
    "import pickle\n",
    "with open(\"GradientDescentOptimizer.bin\", \"wb\") as output:\n",
    "    pickle.dump(weight_grad, output)\n",
    "with open(\"GradientDescentOptimizer.bin\", \"rb\") as data:\n",
    "    weight_grad = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fe2624",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_adam=[\"AdamOptimizer\",epochs,batch_size,val_loss, val_acc,test_loss, test_acc,sess.run(w),sess.run(b)]\n",
    "import pickle\n",
    "with open(\"AdamOptimizer.bin\", \"wb\") as output:\n",
    "    pickle.dump(weight_adam, output)\n",
    "with open(\"AdamOptimizer.bin\", \"rb\") as data:\n",
    "    weight_adam = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ed6528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "    \n",
    "p = PrettyTable()\n",
    "p.field_names = [\"Optimizer\", \"Epoch\", \"Batch_size\",\"loss_val\",\"Accuracy_val\",\"loss_test\",\"accuracy_test\"]\n",
    "p.add_row(weight_grad[0:7])\n",
    "p.add_row(weight_adam[0:7])\n",
    "\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984f5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "+--------------------------+-------+------------+------------+--------------+------------+---------------+\n",
    "|        Optimizer         | Epoch | Batch_size |  loss_val  | Accuracy_val | loss_test  | accuracy_test |\n",
    "+--------------------------+-------+------------+------------+--------------+------------+---------------+\n",
    "| GradientDescentOptimizer |  1000 |    128     | 0.5862813  |    0.8697    | 0.6169034  |     0.8595    |\n",
    "|      AdamOptimizer       |  1000 |    128     | 0.28068522 |    0.9277    | 0.27760762 |     0.9245    |\n",
    "+--------------------------+-------+------------+------------+--------------+------------+---------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e924b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_result(X_true, y_true):\n",
    "    plt.imshow(X_true.reshape(28, 28))\n",
    "    print(np.argmax(y_true))\n",
    "    x_true_flat=X_true.flatten()\n",
    "    print(sess.run(accuracy,feed_dict={x:x_true_flat.reshape(1,784),y:y_true.reshape(1,10)}))\n",
    "    y_preds = sess.run(pred, feed_dict={x : [x_true_flat]})\n",
    "    print(np.argmax(y_preds))\n",
    "    plt.colorbar()\n",
    "show_result(x_test[0], y_test[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
